<source>
  type tail
  format none
  path /var/log/app_engine/app/app*.log
  pos_file /var/tmp/fluentd.app.pos
  read_from_head true
  rotate_wait 10s
  tag app
</source>

<source>
  type tail
  format json
  path /var/log/app_engine/app/app*.json
  pos_file /var/tmp/fluentd.app_json.pos
  read_from_head true
  rotate_wait 10s
  tag app
</source>

<source>
  type tail
  format none
  path /var/log/app_engine/app/request*.log
  pos_file /var/tmp/fluentd.request.pos
  read_from_head true
  rotate_wait 10s
  tag request
</source>

<source>
  type tail
  format none
  path /var/log/app_engine/app/STDOUT*.log
  pos_file /var/tmp/fluentd.STDOUT.pos
  read_from_head true
  rotate_wait 10s
  tag stdout
</source>

<source>
  type tail
  format none
  path /var/log/app_engine/app/STDERR*.log
  pos_file /var/tmp/fluentd.STDERR.pos
  read_from_head true
  rotate_wait 10s
  tag stderr
</source>

<source>
  type tail
  format none
  path /var/log/app_engine/app/custom_logs/*.log
  pos_file /var/tmp/fluentd.custom_logs.pos
  read_from_head true
  rotate_wait 10s
  tag custom.*
</source>

<source>
  type tail
  format json
  path /var/log/app_engine/app/custom_logs/*.json
  pos_file /var/tmp/fluentd.custom_logs_json.pos
  read_from_head true
  rotate_wait 10s
  tag custom.*
</source>

<source>
  type tail
  format none
  path /var/log/app_engine/monitoring/*.log
  pos_file /var/tmp/fluentd.mvm-monitoring.pos
  read_from_head true
  rotate_wait 10s
  tag monitoring.*
</source>

<source>
  type tail
  format none
  path /var/log/syslog
  pos_file /var/tmp/fluentd.syslog.pos
  read_from_head true
  rotate_wait 10s
  tag vm.syslog
</source>

# Parse nginx request (access) logs, which may inc. multiple custom suffixes:
#   tracecontext="(hexadecimal traceId)/options"
#   timestampSeconds="(epoch seconds, floating point)"
#   latencySeconds="(latency)"
# where the / and the options are themselves optional. Instead of using the
# default "format nginx" directive, this uses a custom regex to capture both
# standard and modified nginx logs and add the traceId or latencySeconds if 
# either is found.
<source>
  type tail
  # The default format ends with ..."(?<agent>[^\"]*)")?$/ . This regex is
  # the same as the default up until the end, at which point, before the $,
  # there are optional groups which are specified above.
  # The timeSeconds and timeNanos are used preferentially by cloud logging
  # in place of the standard time capture, which grants us the ability to do
  # sub-second granular logs.
  # When making changes here, test with http://fluentular.herokuapp.com .
  format /^(?<remote>[^ ]*) (?<host>[^ ]*) (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^\"]*) +\S*)?" (?<code>[^ ]*) (?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)")?(?: tracecontext="(?<traceId>[^\/\"]*)[^\"]*")?(?: timestampSeconds="(?<timestampSeconds>[^\.\"]*)\.(?<timestampNanos>[^\"]*)")?(?: latencySeconds="(?<latencySeconds>[^\"]*)")?(?: x-forwarded-for="(?<realClientIP>[^\,\"-]+),?[^\"]*")?.*$/
  time_format %d/%b/%Y:%H:%M:%S %z 
  path /var/log/nginx/access.log
  pos_file /var/tmp/fluentd.nginx-access.pos
  read_from_head true
  rotate_wait 10s
  tag nginx.unmatched
</source>

<filter nginx.unmatched>
  @type record_transformer
  enable_ruby
  <record>
    # If realClientIP is set, use that as the remote.
    remote ${record["realClientIP"] or record["remote"]}
  </record>
</filter>

# Sort nginx logs into reasonable buckets.
<match nginx.unmatched>
  type copy
  <store>
    type rewrite_tag_filter
    rewriterule1 path /_ah/health nginx.health_check
    rewriterule2 path /_ah/vm_health nginx.health_check
    rewriterule3 path /liveness_check nginx.health_check
    rewriterule4 path /readiness_check nginx.health_check
    rewriterule5 path .* nginx.request
  </store>
  <store>
    type rewrite_tag_filter
    rewriterule1 path /_ah/health nginx.health_check_copy
    rewriterule2 path /_ah/vm_health nginx.health_check_copy
    rewriterule3 path /liveness_check nginx.health_check_copy
    rewriterule4 path /readiness_check nginx.health_check_copy
  </store>
</match>

# Save health checks to file on disk every minute
# Path is path + time + .log
<match nginx.health_check_copy>
  type file
  flush_at_shutdown true
  flush_interval 2m
  path /var/log/app_engine/health_check
  time_slice_format %Y%m%d%H%M
</match>

# Parse nginx error logs in the common format
# see http://docs.fluentd.org/articles/common-log-formats
<source>
  type tail
  path /var/log/nginx/error.log

  format multiline
  format_firstline /^\d{4}/\d{2}/\d{2} \d{2}:\d{2}:\d{2} \[\w+\] \d+.\d+: /
  format1 /^(?<time>\d{4}/\d{2}/\d{2} \d{2}:\d{2}:\d{2}) (?<message>.*)/
  multiline_flush_interval 3s
  tag nginx.error
</source>

# Link /var/lib/docker/containers we want to save to /var/log/docker_containers
<source>
  type tail
  path /var/log/saved_docker/*/*-json.log
  pos_file /var/tmp/saved-docker.pos
  time_format %Y-%m-%dT%H:%M:%S
  tag docker.*
  read_from_head true
  format json
</source>

# Do not collect fluentd's own logs to avoid infinite loops.
<match fluent.**>
  type null
</match>

<filter **>
  @type record_transformer
  <record>
    instanceName "#{ENV['GAE_INSTANCE_NAME']}"
  </record>
</filter>

# Transform nginx request (access) log fields into a nested hash suitable
# for consumption by Cloud Logging UI's request_log formatters.
# This extra step is necessary because fluentd regex input cannot be nested.
# An alternative would be to change nginx config to output valid json with
# the correct nested hash keys.
<filter nginx.{health_check,request}>
  type record_transformer
  <record>
    httpRequest {"requestMethod": "${record[\"method\"]}", "referer": "${record[\"referer\"]}", "remoteIp": "${record[\"remote\"]}", "userAgent": "${record[\"agent\"]}", "requestUrl": "${record[\"path\"]}", "responseSize": "${record[\"size\"]}", "status": "${record[\"code\"]}"}
    trace "$traceId"
  </record>
  renew_record true
  keep_keys time,traceId,timestampSeconds,timestampNanos,latencySeconds,instanceName
</filter>

# Docker container logs go through the from_docker container
<match docker.var.log.saved_docker.*.*.log>
  type from_docker
  stdout_tag raw.stdout
  stderr_tag raw.stderr
</match>

# Detect exceptions from stdout and stderr of Docker containers.
<match raw.**>
  type detect_exceptions
  remove_tag_prefix raw
  message message
  multiline_flush_interval 5
  max_bytes 50000
  max_lines 500
</match>

<match **>
  type google_cloud
  buffer_chunk_limit 1m
  flush_interval 5s
  # Never wait longer than 5 minutes between retries
  max_retry_wait 300
  disable_retry_limit
  # Send these fields as labels instead of in the struct_payload
  label_map {
    "thread": "appengine.googleapis.com/thread_id",
    "traceId": "appengine.googleapis.com/trace_id",
    "instanceName": "appengine.googleapis.com/instance_name"
  }
  use_grpc true
</match>
